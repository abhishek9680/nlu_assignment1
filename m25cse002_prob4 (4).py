# -*- coding: utf-8 -*-
"""m25cse002_prob4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_UEqNoKAwZXv2UgUftNykC-g3aYSiZRw
"""

# Binary Text Classification: Sports vs Politics


import re
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC


#text cleaning
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    words = text.strip().split()
    words = [w for w in words if len(w) > 2]
    return " ".join(words)


#load dataset
def load_data():

    categories = [
        "rec.sport.baseball",
        "rec.sport.hockey",
        "talk.politics.guns",
        "talk.politics.misc",
        "talk.politics.mideast"
    ]

    dataset = fetch_20newsgroups(
        subset="all",
        categories=categories,
        remove=("headers", "footers", "quotes"),
        random_state=42
    )

    texts = [clean_text(t) for t in dataset.data]

    labels = np.array([
        0 if "sport" in dataset.target_names[target] else 1
        for target in dataset.target
    ])

    print("Total Samples:", len(texts))
    print("Sports:", np.sum(labels == 0))
    print("Politics:", np.sum(labels == 1))

    return texts, labels


#main function
def main():

    texts, labels = load_data()

    X_train, X_test, y_train, y_test = train_test_split(
        texts,
        labels,
        test_size=0.3,
        stratify=labels,
        random_state=42
    )

    #tf for all model
    vectorizer = TfidfVectorizer(
        stop_words="english",
        ngram_range=(1,2),
        max_df=0.9,
        min_df=2
    )

    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)

    #model defining
    models = {
        "Naive Bayes": MultinomialNB(alpha=1.0),
        "Logistic Regression": LogisticRegression(max_iter=1500, C=1.0),
        "Linear SVM": LinearSVC(C=1.5)
    }

    results = {}

    print("\n========== MODEL COMPARISON ==========")

    for name, model in models.items():

        model.fit(X_train_vec, y_train)
        preds = model.predict(X_test_vec)

        acc = accuracy_score(y_test, preds)
        f1 = f1_score(y_test, preds, average="weighted")

        # 5-Fold Cross Validation Score
        cv_score = cross_val_score(model, X_train_vec, y_train, cv=5).mean()

        print(f"\n{name}")
        print("Test Accuracy:", round(acc, 4))
        print("Weighted F1 Score:", round(f1, 4))
        print("5-Fold CV Accuracy:", round(cv_score, 4))
        print(classification_report(y_test, preds,
                                    target_names=["Sports", "Politics"]))

        results[name] = cv_score

        # Confusion Matrix
        cm = confusion_matrix(y_test, preds)
        plt.figure(figsize=(4,3))
        sns.heatmap(cm, annot=True, fmt="d",
                    cmap="YlGnBu",
                    xticklabels=["Sports", "Politics"],
                    yticklabels=["Sports", "Politics"])
        plt.title(name)
        plt.show()

    #accuracy comparison graph
    plt.figure(figsize=(6,4))
    bars = plt.bar(results.keys(),
                   results.values(),
                   color=["#4C72B0", "#55A868", "#C44E52"])

    plt.ylabel("Cross Validation Accuracy")
    plt.title("Model Comparison (5-Fold CV)")
    plt.ylim(0.85, 1.0)

    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2,
                 height + 0.003,
                 f"{height:.3f}",
                 ha='center')

    plt.show()

    #selecting best model
    best_model_name = max(results, key=results.get)
    print("\nBest Model Selected:", best_model_name)

    final_model = models[best_model_name]

    # Train on full dataset
    X_full = vectorizer.fit_transform(texts)
    final_model.fit(X_full, labels)

    #interaction
    print("\nInteractive Classification Mode")
    print("Type 'exit' to stop")

    feature_names = vectorizer.get_feature_names_out()

    while True:

        user_input = input("\nEnter a sentence: ")

        if user_input.lower() == "exit":
            print("Exiting classifier...")
            break

        if not user_input.strip():
            print("Please enter valid text.")
            continue

        cleaned = clean_text(user_input)
        transformed = vectorizer.transform([cleaned])
        prediction = final_model.predict(transformed)[0]

        label_name = "Sports" if prediction == 0 else "Politics"
        print("Predicted Category:", label_name)

        # Show influential words for linear models like politics an
        if hasattr(final_model, "coef_"):
            coefs = final_model.coef_[0]
            indices = transformed.nonzero()[1]

            print("Influential Words:")
            for i in indices[:10]:
                weight = coefs[i]
                word = feature_names[i]
                if weight > 0:
                    print(f"{word} → Politics")
                else:
                    print(f"{word} → Sports")


if __name__ == "__main__":
    main()

